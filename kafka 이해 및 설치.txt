[Quickstart]
 - zookeeper는 카프카의 노드를 관리해주고, 토픽의 offset 정보등을 저장하기 위해 필요
 - zookeeper는 과반수 투표방식으로 결정하기 때문에 홀수로 구성해야 하고, 과반수 이상 살아 있으면 정상으로 동작
 - kafka는 과반수 투표방식을 사용하지 않지만, Replication Factor를 3으로 할 경우, 균일하게 스프레드하기 위해서
  노드 수 3이 최소라고 생각(__consumer_offsets 토픽은 기본값이 RF3)
 - kafka를 다운로드한 후, 압축을 풀면 주키퍼와 카프카가 포함되어 있음. kafka는 scala로 만들어져 있고, JVM위에서 동작함
 - zookeeper의 경우는 kafka에 포함되어 있느 버전을 사용해도 되고, 오픈소스 버전을 이용해도 됨
 - tar - zxf kafka_2.11-0.10.1.0.tgz > cd kafka_2.11-0.10.1.0
 - 주키퍼 config : vi config/zookeeper.properties 
 - 카프카 config : vi config/server.properties 
 - 주키퍼 시작 : bin/zookeeper-server-start.sh config/zookeeper.properties
 - 카프카 시작 : bin/kafka-server-start.sh config/server.properties
 - 주키퍼 데몬 시작 : bin/zookeeper-server-start.sh -daemon config/zookeeper.properties
 - 카프카 데몬 시작 : bin/kafka-server-start.sh -daemon config/server.properties 
 - topic 만들기 
   . 카프카에서 토픽은 데이터베이스의 table정도의 개념으로 생각하시면 될 것 같음
   . 카프카에 저장되는 데이터를 토픽이라는 이름으로 구분하기 위해서 사용함
   . replica 2 or 3은 2개 or 3개로 복제할것인지를 의미함
   . partition은 토픽을 몇개로 나눌지를 의미함
   . 여기서는 테스트를 위해 1 replica, 1 partition으로 만들어봄 
   . bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test 
   . Created topic "test". -> 이런 메시지가 나타나면,  완료입니다.
   . 커맨드를 이용하여 zookeeper에 해당 토픽이 생성되어 있는 지 확인함
   . bin/kafka-topics.sh --list --zookeeper localhost:2181
   . consumer_offsets는 offset을 주키퍼가 아닌 카프카의 토픽으로 저장할때 사용하는 토픽이며, 자동으로 생성되는 토픽임
 - 메시지 보내기
   . bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
 - 메시지 가져오기
   . bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning

[Partition 수에 따른 메시지 순서]
 - 파티션의 수를 8로 주고 새로운 토픽 test8로 만들어 보겠음
 - 파티션 수를 8로 준것은 큰 의미없이, 카프카 default 값을 따라한 것임
 - bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 8 --topic test8 
 - 숫자 하나로 1 ~ 8까지 메시지를 보내보겠음
 - bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test8
   1
   2
   3
   4
   5
   6
   7
   8
 - bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test8 --from-beginning
   1
   3
   3
   5
   4
   6
   8
   7
 - 하나의 파티션에 대해서 데이터의 순서를 보장합
 - 만약 토픽에 대해 모든 데이터의 순서를 보장받고 싶다면, 토픽을 생성할때 파티션의 수를 1로 토픽을 생성하면 됨
 - 컨슈머는 각각의 파티션에서 첫번째 데이터를 가져올 뿐이지, 파티션의 순서대로 가져오지는 않음
 
   
[기본설명 및 기존 메시징 시스템과 다른 점]
 - 메세징 큐의 일종
 - 말 그대로 분산형 스트리밍 플랫폼, LinkedIn에서 여러 구직 + 채용 정보들을 한곳에서 처리(발행/구독)할수 있는 플랫폼으로 개발이 시작
 - 대용량의 실시간 로그 처리에 특화되어 설계된 메시징 시스템, 기존 범용 메시징 시스템대비 TPS가 매우 우수
 - 메시지를 기본적으로 메모리에 저장하는 기존 메시징 시스템과는 달리 메시지를 파일 시스템에 저장 → 카프카 재시작으로 인한 메세지 유실 우려 감소
 - 기존의 메시징 시스템에서는 broker가 consumer에게 메시지를 push해 주는 방식인데 반해, 
   Kafka는 consumer가 broker로부터 직접 메시지를 가지고 가는 pull 방식으로 동작하기 때문에 
   consumer는 자신의 처리능력만큼의 메시지만 broker로부터 가져오기 때문에 최적의 성능을 낼 수 있음

[카프카 주요 개념]
 - producer : 메세지 생산(발행)자.
 - consumer : 메세지 소비자
 - consumer group : consumer 들끼리 메세지를 나눠서 가져간다.offset 을 공유하여 중복으로 가져가지 않는다.
 - broker : 카프카 서버를 가리킴
 - zookeeper : 카프카 서버 (+클러스터) 상태를 관리하고
 - cluster : 브로커들의 묶음
 - topic : 메세지 종류
 - partitions : topic 이 나눠지는 단위
 - Log : 1개의 메세지
 - offset : 파티션 내에서 각 메시지가 가지는 unique id

[카프카는 어떤식으로 돌아가는가]
 - zookeeper 가 kafka 의 상태와 클러스터 관리를 해줌
 - 정해진 topic 에 producer 가 메세지를 발행해놓으면 consumer 가 필요할때 해당 메세지를 가져간다.
  (여기서 카프카로 발행된 메세지들은 consumer가 메세지를 소비한다고 해서 없어지는게 아니라 카프카 설정log.retention.hours(default : 168[7일])에 의해 삭제된다.)   
 - 가장 적절한 개수는 정해지지 않았지만 통상 컨슈머그룹의 컨슈머 개수와 파티션 개수를 동일하게 가져가곤 함 
 
 
  
[zookeeper, kafka 실행]
 - 참조 : https://miiingo.tistory.com/196
 - kafka-with-docker 디렉토리 생성하고 zookeeper 및 kafka 컨테이너를 실행하기 위한 docker-compose.yaml 파일 작성
   cd /opt/gopath/src/github.com/
   mkdir kafka-with-docker
   
   cd /opt/gopath/src/github.com/kafka-with-docker
   vi docker-compose.yaml

 - kafka 환경변수
   . KAFKA_ADVERTISED_LISTENERS : kafka 브로커를 가리키는 사용 가능 주소 목록. kafka는 초기 연결 시 이를 client에게 보냄   예) PLAINTEXT://localhost:9002
   . KAFKA_LISTENERS : kafka 브로커가 들어오는 연결을 수신 대기하는 주소 및 리스너 이름 목록   예) PLAINTEXT://0.0.0.0:9092     
   . KAFKA_ZOOKEEPER_CONNECT : ZooKeeper 연결 문자열. ,로 구분 ex) <zookeeper서버의 hostname>:<zookeeper서버의 포트번호> 예) zookeeper:2181
   . KAFKA_CREATE_TOPICS : 생성할 Topic명:Partition 개수:Replica 개수 예) "javainuse-topic:1:1" 
   
version: '2'

networks:
  test:

services:
  zookeeper:
    image: wurstmeister/zookeeper:3.4.6
    container_name: zookeeper
    ports:
      - "2181:2181"
    networks:
      - test

  kafka:
    image: wurstmeister/kafka:2.12-2.4.0
    container_name: kafka
    environment:
      KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092
      KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_HOST_NAME=127.0.0.1
      KAFKA_ADVERTISED_PORT=9092
      KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      KAFKA_CREATE_TOPICS=javainuse-topic:1:1   # Topic명:Partition개수:Replica개수
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - "9092:9092"
    depends_on:
      - zookeeper
    networks:
      - test   
   
 - zookeeper&kafka 켄테이너 실행
   . 작성한 docker-compose.yaml 파일을 이용해 zookeeper 및 kafka 컨테이너를 실행함
   . $ cd /opt/gopath/src/github.com/kafka-with-docker
   . zookeeper&kafka 컨테이너 실행 : $ docker-compose up -d
   . zookeeper&kafka 컨테이너 중지 : $ docker-compose down
 - zookeeper 컨테이너 로그 확인
   . $ docker container logs zookeeper
 - kafka 컨테이너 로그 확인
   . $ docker container logs kafka
         
 - kafka 실행 확인
   . 위의 docker-compose.yaml 파일에서 kafka 실행 이미지를 wurstmeister/kafka:2.12-2.0.1로 설정했기 때문에
     이와 동일한 버전의 kafka 바이너리 파일을 다운로드함
   . 이를 위해 kafka 컨테이너의 이미지 버전을 latest가 아닌 고정된 버전으로 사용하는 것을 추천함
   . $ cd /opt/gopath/src/github.com/kafka-with-docker
   . $ wget http://mirror.navercorp.com/apache/kafka/2.4.0/kafka_2.12-2.4.0.tgz
   . $ tar -zxvf kafka_2.12-2.4.0.tgz
   . $ rm kafka_2.12-2.0.1.tgz   
 - kafka topic 생성 확인
   . $ cd /opt/gopath/src/github.com/kafka-with-docker/kafka_2.12-2.0.1
   . $ sh bin/kafka-topics.sh --zookeeper localhost:2181 --list   
   . 실행 옵션
     --zookeeper : zookeeper가 실행 중인 호스트. 별도의 서버에 구축했다면 server_ip:server_port로 지정
     --list : 리스트 출력
     --create : topic 생성
     --topic : 생성할 topic명
     --partitions : 생성할 topic의 파티션 개수
     --replication-factor : 생성할 topic의 복사본 개수
 - kafka consumer 실행
   . $ cd /opt/gopath/src/github.com/kafka-with-docker/kafka_2.12-2.0.1
   . $ bin/kafka-console-consumer.sh --topic javainuse-topic --bootstrap-server localhost:9092 --from-beginning     
   . 실행 옵션
     --topic : 메시지를 가져올 topic. 여기에선 kafka 컨테이너 실행 시에 생성한 javainuse-topic으로 설정
     --bootstrap-server : kafka가 실행 중인 호스트. 별도의 서버에 구축했다면 server_ip:server_port로 지정
     --from-beginning : 맨 처음부터 메시지를 가져옴
 - kafka producer 실행
   . $ cd /opt/gopath/src/github.com/kafka-with-docker/kafka_2.12-2.0.1
   . $ bin/kafka-console-producer.sh --topic javainuse-topic --broker-list localhost:9092
   . 실행 옵션
     --topic : 메시지를 생산할 topic. 여기에선 kafka 컨테이너 실행 시에 생성한 javainuse-topic으로 설정
     --broker-list : kafka가 실행 중인 호스트. 별도의 서버에 구축했다면 server_ip:server_port로 지정
     


     
     
     
     
   
   
   
   
